{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c154a88",
   "metadata": {},
   "source": [
    "# 1.Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24004826",
   "metadata": {},
   "source": [
    "## 1.1 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc31caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import spacy\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd95b91",
   "metadata": {},
   "source": [
    "## 1.2 Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665e96b1",
   "metadata": {},
   "source": [
    "### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb38a7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load our train data into a dataFrame\n",
    "trainDf = pd.read_excel('resources/referentiel_foodex.xlsx',sheet_name='Feuil1')\n",
    "trainDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4811c8d4",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2960dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the test.json into an Excel file to be easy to annoutate.\n",
    "with open(\"resources/test.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "products = data[\"designations\"]\n",
    "testDf = pd.DataFrame({\n",
    "    \"Product\": products,\n",
    "    \"Category_clean\": [\"\"] * len(products)\n",
    "})\n",
    "testDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56911e94",
   "metadata": {},
   "source": [
    "## 1.3 Cleaning steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb97173",
   "metadata": {},
   "source": [
    "### Duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cccf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are duplicated rows \n",
    "# No duplicated rows in train\n",
    "\n",
    "duplicates = trainDf[trainDf.duplicated()]\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0d063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No duplicated rows in test\n",
    "\n",
    "duplicates = testDf[testDf.duplicated()]\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3565fb",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fa8a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No missing values in test\n",
    "testDf.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 missing values in train\n",
    "trainDf.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f01bf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There 3 missing categories, for the moment we just remove them \n",
    "#-> (any row that has a missing value in a column will be dropped)\n",
    "\n",
    "trainDf_Cleaned = trainDf.dropna()\n",
    "trainDf_Cleaned = trainDf_Cleaned.rename(columns={\n",
    "    'Désignation commerciale':'Product',\n",
    "    'Catégorie de référence':'Category'})\n",
    "trainDf_Cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8613c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDf_Cleaned = testDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec611cb6",
   "metadata": {},
   "source": [
    "### Scientific names handeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08b6cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_scientific_names(text):\n",
    "    # Use regex to find and remove all text between parentheses (scientific names)\n",
    "    cleaned_text = re.sub(r'\\(.*?\\)', '', text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a023f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf_Cleaned[\"Product_clean\"] = trainDf_Cleaned[\"Product\"].apply(remove_scientific_names)\n",
    "trainDf_Cleaned[\"Category_clean\"] = trainDf_Cleaned[\"Category\"].apply(remove_scientific_names)\n",
    "trainDf_Cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce104a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDf_Cleaned[\"Product_clean\"] = testDf_Cleaned[\"Product\"].apply(remove_scientific_names)\n",
    "testDf_Cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7a6035",
   "metadata": {},
   "source": [
    "### Special caracters and Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c558c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    text = re.sub(r\"[^a-zA-Z0-9àâäéèêëîïôöùûüÿçœæÀÂÄÉÈÊËÎÏÔÖÙÛÜŸÇŒÆ\\s]\",\" \",text) # Replace special caracters with white space.\n",
    "    return text.lower() # lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5308de26",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf_Cleaned[\"Product_clean\"] = trainDf_Cleaned[\"Product_clean\"].apply(cleanText)\n",
    "trainDf_Cleaned[\"Category_clean\"] = trainDf_Cleaned[\"Category_clean\"].apply(cleanText)\n",
    "trainDf_Cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5d2849",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDf_Cleaned[\"Product_clean\"] = testDf_Cleaned[\"Product_clean\"].apply(cleanText)\n",
    "testDf_Cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17372f9e",
   "metadata": {},
   "source": [
    "### Stopwords removing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daca21db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download French stopwords if not already\n",
    "nltk.download('stopwords')\n",
    "french_stopwords = set(stopwords.words('french'))\n",
    "len(french_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79aee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_french_stopwords(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    return ' '.join([w for w in words if w not in french_stopwords])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9c4616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to both columns\n",
    "trainDf_Cleaned['Product_clean'] = trainDf_Cleaned['Product_clean'].apply(remove_french_stopwords)\n",
    "trainDf_Cleaned['Category_clean'] = trainDf_Cleaned['Category_clean'].apply(remove_french_stopwords)\n",
    "trainDf_Cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9251b0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDf_Cleaned[\"Product_clean\"] = testDf_Cleaned[\"Product_clean\"].apply(remove_french_stopwords)\n",
    "testDf_Cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456994ac",
   "metadata": {},
   "source": [
    "### Keep only Nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d186ae8c",
   "metadata": {},
   "source": [
    "use the following command to install the model :\n",
    "\n",
    "```bash\n",
    "uv run python -m spacy download fr_dep_news_trf \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f30706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_dep_news_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50db4102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_nouns(text):\n",
    "    doc = nlp(text)\n",
    "    cleanedText = \" \".join([token.text for token in doc if token.pos_ in [\"NOUN\",\"PROPN\"] ])\n",
    "    if len(cleanedText) > 0:\n",
    "        return cleanedText\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47991099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example \n",
    "\n",
    "print(keep_nouns(\"boissons au cola caféiniques faibles en \"))\n",
    "\n",
    "doc = nlp(\"boissons au cola caféiniques faibles en \")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2638458",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf_Cleaned[\"Product_clean\"] = trainDf_Cleaned[\"Product_clean\"].apply(keep_nouns)\n",
    "trainDf_Cleaned[\"Category_clean\"] = trainDf_Cleaned[\"Category_clean\"].apply(keep_nouns)\n",
    "trainDf_Cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c18d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDf_Cleaned[\"Product_clean\"] = testDf_Cleaned[\"Product_clean\"].apply(keep_nouns)\n",
    "testDf_Cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0581fb0",
   "metadata": {},
   "source": [
    "### Redundant words handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9d8e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_redundant_words(text):\n",
    "    words = text.split()\n",
    "    unique_words = set(words)\n",
    "    cleaned_text = ' '.join(sorted(unique_words, key=words.index))\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94dacd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf_Cleaned[\"Product_clean\"] = trainDf_Cleaned[\"Product_clean\"].apply(remove_redundant_words)\n",
    "trainDf_Cleaned[\"Category_clean\"] = trainDf_Cleaned[\"Category_clean\"].apply(remove_redundant_words)\n",
    "trainDf_Cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5f8a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDf_Cleaned[\"Product_clean\"] = testDf_Cleaned[\"Product_clean\"].apply(remove_redundant_words)\n",
    "testDf_Cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747a4104",
   "metadata": {},
   "source": [
    "### Save the cleaned dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774f8d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf_Cleaned.iloc[:, -2:].to_excel('data/train_cleaned.xlsx',index=False)\n",
    "testDf_Cleaned.to_excel('data/test_cleaned.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb43da1",
   "metadata": {},
   "source": [
    "# 2.Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad88a981",
   "metadata": {},
   "source": [
    "## 2.1 Evaluation function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824528cf",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f3f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0529b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDf_Cleaned = pd.read_excel('data/test_cleaned.xlsx')\n",
    "trainDf_Cleaned = pd.read_excel('data/train_cleaned.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae04d23",
   "metadata": {},
   "source": [
    "### Preparing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea11cd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Product_clean</th>\n",
       "      <th>Category_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lait au chocolat</td>\n",
       "      <td>lait chocolat</td>\n",
       "      <td>chocolat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Poisson en chocolat</td>\n",
       "      <td>poisson chocolat</td>\n",
       "      <td>produits chocolat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chocapic en poudre</td>\n",
       "      <td>chocapic poudre</td>\n",
       "      <td>poudre cacao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cola light sans bulles</td>\n",
       "      <td>cola bulles</td>\n",
       "      <td>boissons calories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jus de pomme bio</td>\n",
       "      <td>jus pomme</td>\n",
       "      <td>jus pomme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Crème brûlée vanille</td>\n",
       "      <td>crème vanille</td>\n",
       "      <td>collations desserts aliments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Macaron framboise</td>\n",
       "      <td>macaron framboise</td>\n",
       "      <td>pâtisseries gâteaux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Tarte tatin</td>\n",
       "      <td>tarte</td>\n",
       "      <td>tarte fruits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Clafoutis aux cerises</td>\n",
       "      <td>clafoutis cerises</td>\n",
       "      <td>gâteau fruits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Panna cotta fruits rouges</td>\n",
       "      <td>panna cotta fruits</td>\n",
       "      <td>collations desserts aliments</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Product       Product_clean  \\\n",
       "0            Lait au chocolat       lait chocolat   \n",
       "1         Poisson en chocolat    poisson chocolat   \n",
       "2          Chocapic en poudre     chocapic poudre   \n",
       "3      Cola light sans bulles         cola bulles   \n",
       "4            Jus de pomme bio           jus pomme   \n",
       "..                        ...                 ...   \n",
       "95       Crème brûlée vanille       crème vanille   \n",
       "96          Macaron framboise   macaron framboise   \n",
       "97                Tarte tatin               tarte   \n",
       "98      Clafoutis aux cerises   clafoutis cerises   \n",
       "99  Panna cotta fruits rouges  panna cotta fruits   \n",
       "\n",
       "                  Category_clean  \n",
       "0                       chocolat  \n",
       "1              produits chocolat  \n",
       "2                   poudre cacao  \n",
       "3              boissons calories  \n",
       "4                      jus pomme  \n",
       "..                           ...  \n",
       "95  collations desserts aliments  \n",
       "96           pâtisseries gâteaux  \n",
       "97                  tarte fruits  \n",
       "98                 gâteau fruits  \n",
       "99  collations desserts aliments  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map knowen categories from train data by merging on Product_clean column\n",
    "\n",
    "testDf_Cleaned = testDf_Cleaned.drop(columns=[\"Category_clean\"])  # drop the empty column\n",
    "testDf_Cleaned = testDf_Cleaned.merge(trainDf_Cleaned, on=\"Product_clean\", how=\"left\")\n",
    "testDf_Cleaned.to_excel('data/test_cleaned.xlsx',index=False)\n",
    "testDf_Cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7c3f22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Product_clean</th>\n",
       "      <th>Category_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lait au chocolat</td>\n",
       "      <td>lait chocolat</td>\n",
       "      <td>chocolat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Poisson en chocolat</td>\n",
       "      <td>poisson chocolat</td>\n",
       "      <td>produits chocolat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chocapic en poudre</td>\n",
       "      <td>chocapic poudre</td>\n",
       "      <td>poudre cacao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cola light sans bulles</td>\n",
       "      <td>cola bulles</td>\n",
       "      <td>boissons calories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jus de pomme bio</td>\n",
       "      <td>jus pomme</td>\n",
       "      <td>jus pomme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Crème brûlée vanille</td>\n",
       "      <td>crème vanille</td>\n",
       "      <td>collations desserts aliments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Macaron framboise</td>\n",
       "      <td>macaron framboise</td>\n",
       "      <td>pâtisseries gâteaux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Tarte tatin</td>\n",
       "      <td>tarte</td>\n",
       "      <td>tarte fruits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Clafoutis aux cerises</td>\n",
       "      <td>clafoutis cerises</td>\n",
       "      <td>gâteau fruits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Panna cotta fruits rouges</td>\n",
       "      <td>panna cotta fruits</td>\n",
       "      <td>collations desserts aliments</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Product       Product_clean  \\\n",
       "0            Lait au chocolat       lait chocolat   \n",
       "1         Poisson en chocolat    poisson chocolat   \n",
       "2          Chocapic en poudre     chocapic poudre   \n",
       "3      Cola light sans bulles         cola bulles   \n",
       "4            Jus de pomme bio           jus pomme   \n",
       "..                        ...                 ...   \n",
       "95       Crème brûlée vanille       crème vanille   \n",
       "96          Macaron framboise   macaron framboise   \n",
       "97                Tarte tatin               tarte   \n",
       "98      Clafoutis aux cerises   clafoutis cerises   \n",
       "99  Panna cotta fruits rouges  panna cotta fruits   \n",
       "\n",
       "                  Category_clean  \n",
       "0                       chocolat  \n",
       "1              produits chocolat  \n",
       "2                   poudre cacao  \n",
       "3              boissons calories  \n",
       "4                      jus pomme  \n",
       "..                           ...  \n",
       "95  collations desserts aliments  \n",
       "96           pâtisseries gâteaux  \n",
       "97                  tarte fruits  \n",
       "98                 gâteau fruits  \n",
       "99  collations desserts aliments  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data after annoutating remained Products\n",
    "testDf_Cleaned = pd.read_excel('data/test_cleaned.xlsx')\n",
    "testDf_Cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20068e5",
   "metadata": {},
   "source": [
    "### Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f936f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluate(true_df, pred_df):\n",
    "    merged = true_df.merge(pred_df, on=\"Product_clean\", how=\"inner\")\n",
    "    y_true = merged[\"Category_clean\"]\n",
    "    y_pred = merged[\"Category_predicted\"]\n",
    "    return accuracy_score(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e11300",
   "metadata": {},
   "source": [
    "## 2.2 Keywords based Pre-Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c046c1c",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c662b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf = pd.read_excel('data/train_cleaned.xlsx')\n",
    "trainDf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde597d5",
   "metadata": {},
   "source": [
    "### Get Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Candidates(productName):\n",
    "    categories = trainDf['Category_clean'].tolist()\n",
    "    candidates = set()\n",
    "    keywords = productName.strip().split()\n",
    "    for keyword in keywords:\n",
    "        for category in categories:\n",
    "            if keyword in category.strip().split():\n",
    "                candidates.add(category)\n",
    "    return list(candidates)\n",
    "\n",
    "def runAll():\n",
    "    products = trainDf['Product_clean'].tolist()\n",
    "    candidates_list = []\n",
    "    for product in products:\n",
    "        candidates = get_Candidates(product)\n",
    "        candidates_list.append(candidates)\n",
    "    trainDf['Candidate_categories'] = candidates_list\n",
    "    return trainDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "get_Candidates(\"purée pommes terre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c83e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_candidates = runAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682d290f",
   "metadata": {},
   "source": [
    "### Set predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c48095",
   "metadata": {},
   "source": [
    "If a product has only one candidate, there is no need for the refinement step, as the predicted category is already determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_candidates['Category_predicted'] = train_with_candidates['Candidate_categories'].apply(\n",
    "    lambda x: x[0] if len(x) == 1 else ''\n",
    ")\n",
    "train_with_candidates.to_excel('data/train_with_candidates.xlsx',index=False)\n",
    "train_with_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b4f7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2896c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6375e355",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-technique-chemosens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
