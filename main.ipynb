{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c154a88",
   "metadata": {},
   "source": [
    "# 1.Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd95b91",
   "metadata": {},
   "source": [
    "## 1.1 Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb38a7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load our train data into a dataFrame\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "trainDf = pd.read_excel('resources/referentiel_foodex.xlsx',sheet_name='Feuil1')\n",
    "trainDf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56911e94",
   "metadata": {},
   "source": [
    "## 1.2 Cleaning steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb97173",
   "metadata": {},
   "source": [
    "### Duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cccf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are duplicated rows \n",
    "# No duplicated rows \n",
    "\n",
    "duplicates = trainDf[trainDf.duplicated()]\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3565fb",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much missing values\n",
    "trainDf.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f01bf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There 3 missing categories, for the moment we just remove them \n",
    "#-> (any row that has a missing value in a column will be dropped)\n",
    "\n",
    "trainDf_Cleaned = trainDf.dropna()\n",
    "trainDf_Cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7a6035",
   "metadata": {},
   "source": [
    "### Special caracters and Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c558c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cleanText(text):\n",
    "    text = re.sub(r\"[^a-zA-Z0-9àâäéèêëîïôöùûüÿçœæÀÂÄÉÈÊËÎÏÔÖÙÛÜŸÇŒÆ\\s]\",\" \",text) # Replace special caracters with white space.\n",
    "    return text.lower() # lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5308de26",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf_Cleaned = trainDf_Cleaned.map(cleanText)\n",
    "trainDf_Cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747a4104",
   "metadata": {},
   "source": [
    "### Save the cleaned dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774f8d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before saving we need to rename columns\n",
    "\n",
    "trainDf_Cleaned = trainDf_Cleaned.rename(columns={\n",
    "    'Désignation commerciale':'Product_Name',\n",
    "    'Catégorie de référence':'Raw_Category'})\n",
    "\n",
    "trainDf_Cleaned.to_excel('data/train.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aab18cc",
   "metadata": {},
   "source": [
    "## 1.3 Working on Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ccf159",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a858603a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time \n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db757b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a API client and we get the previous dataframe\n",
    "\n",
    "client = genai.Client(api_key=os.getenv('GEMINI_API_KEY'))\n",
    "trainDF = pd.read_excel('data/train.xlsx',sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abf0cc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getEmbedding : returns the embeddings of a list of sentences, output is an array of shape (len(texts),768)\n",
    "\n",
    "def getEmbedding(texts:list):\n",
    "    result = [\n",
    "    np.array(e.values) for e in client.models.embed_content(\n",
    "        model=\"gemini-embedding-001\",\n",
    "        contents=texts,\n",
    "        config=types.EmbedContentConfig(task_type=\"SEMANTIC_SIMILARITY\",output_dimensionality=768)).embeddings\n",
    "    ]\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd27f8f",
   "metadata": {},
   "source": [
    "### Get Embeddings of raw categories and cleaned-categories-definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of grouped categories : 14\n"
     ]
    }
   ],
   "source": [
    "# Raw and cleaned categories\n",
    "\n",
    "cleaned_categories = [\n",
    "    \"boissons\",\n",
    "    \"pains\",\n",
    "    \"patisserie\",\n",
    "    \"céréales et dérivés\",\n",
    "    \"produits laitiers\",\n",
    "    \"viandes et préparations\",\n",
    "    \"poissons et fruits de mer\",\n",
    "    \"fruits et dérivés\",\n",
    "    \"légumes et dérivés\",\n",
    "    \"snacks\",\n",
    "    \"plats préparés\",\n",
    "    \"œufs et préparations\",\n",
    "    \"produits de cacao\",\n",
    "    \"sauces\"\n",
    "    ]\n",
    "cleaned_categories_definitions = [\n",
    "    \"boissons chaudes ou froides, incluant eau, jus, café, thé, sodas et infusions\",\n",
    "    \"pains, baguettes, brioches et autres produits de boulangerie de base\",\n",
    "    \"pâtisseries sucrées comme gâteaux, viennoiseries, tartes et desserts\",\n",
    "    \"céréales, riz, pâtes, farines et produits céréaliers transformés\",\n",
    "    \"produits laitiers tels que lait, fromage, yaourt, crème et beurre\",\n",
    "    \"viandes, volailles, charcuteries, fraîches ou transformées\",\n",
    "    \"poissons et fruits de mer, frais, fumés, en conserve ou surgelés\",\n",
    "    \"fruits frais, secs, en jus ou transformés\",\n",
    "    \"légumes frais, secs, en conserve, surgelés ou transformés\",\n",
    "    \"snacks salés ou sucrés comme chips, biscuits, barres et confiseries\",\n",
    "    \"plats préparés, prêts à consommer, frais, en conserve ou surgelés\",\n",
    "    \"œufs et produits à base d’œufs comme omelettes, poudres ou préparations\",\n",
    "    \"cacao, chocolat, poudres et produits dérivés\",\n",
    "    \"sauces prêtes à l’emploi ou préparées, comme ketchup, mayonnaise, moutarde, sauces tomate et condiments\"\n",
    "]\n",
    "raw_categories = trainDF['Raw_Category'].tolist()\n",
    "\n",
    "print(\"Number of grouped categories :\",len(cleaned_categories))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e30a6d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleep for 60 seconds for api limits reasons\n",
      "Shape of similarities matrix :  (97, 14)\n"
     ]
    }
   ],
   "source": [
    "# Apply getEmbedding\n",
    "\n",
    "cleaned_categories_definitions_embeddings = getEmbedding(cleaned_categories_definitions)\n",
    "\n",
    "print(\"Sleep for 60 seconds for api limits reasons\")\n",
    "time.sleep(60)\n",
    "\n",
    "raw_categories_embeddings     = getEmbedding(raw_categories)\n",
    "\n",
    "# Compute cosine similarities between raw and cleaned embeddings\n",
    "\n",
    "similarities = cosine_similarity(raw_categories_embeddings, cleaned_categories_definitions_embeddings)\n",
    "\n",
    "print(\"Shape of similarities matrix : \",similarities.shape)\n",
    "\n",
    "# Find the index of highest similarity for each raw embedding\n",
    "\n",
    "best_match_idx = similarities.argmax(axis=1)\n",
    "best_match_score = similarities.max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c1f994",
   "metadata": {},
   "source": [
    "### Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "086a956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping indexes to corresponding cleaned_categories, put the results in a dictionary\n",
    "\n",
    "category_mapping = []\n",
    "for index,raw_category in enumerate(raw_categories):\n",
    "    category_mapping.append(\n",
    "        {\n",
    "            'raw_category':raw_category,\n",
    "            'cleaned_category':cleaned_categories[best_match_idx[index]],\n",
    "            'similarity_score':best_match_score[index]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "# Save the results\n",
    "\n",
    "map_df = pd.DataFrame(category_mapping)\n",
    "result = trainDF.merge(map_df,\n",
    "                       left_on=\"Raw_Category\",\n",
    "                       right_on=\"raw_category\",\n",
    "                       how=\"left\")\n",
    "result = result.drop(columns=[\"raw_category\"])\n",
    "result.to_excel('data/train_grouped_categories.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64865705",
   "metadata": {},
   "source": [
    "# 2. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaa4c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-technique-chemosens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
